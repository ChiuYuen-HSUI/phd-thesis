\input{common/header.tex}
\inbpdocument

\chapter{Appendix for Grammars}


\section{Kernels}

\subsection{Base kernels}

For scalar-valued inputs, the white noise ($\kWN$), constant ($\kC$), linear ($\kLin$), squared exponential ($\kSE$), and periodic kernels ($\kPer$) are defined as follows:
\begin{eqnarray}
\kWN(\inputVar, \inputVar') =& \sigma^2\delta_{\inputVar, \inputVar'} \\
\kC(\inputVar, \inputVar') =& \sigma^2 \\
\kLin(\inputVar, \inputVar') =& \sigma^2(\inputVar - \ell)(\inputVar' - \ell) \\
\kSE(\inputVar, \inputVar') =& \sigma^2\exp\left(-\frac{(\inputVar - \inputVar')^2}{2\ell^2}\right) \\
\kPer(\inputVar, \inputVar') =&  \sigma^2\frac{\exp\left(\frac{\cos\frac{2 \pi (\inputVar - \inputVar')}{p}}{\ell^2}\right) - I_0\left(\frac{1}{\ell^2}\right)}{\exp\left(\frac{1}{\ell^2}\right) - I_0\left(\frac{1}{\ell^2}\right)}
\end{eqnarray}
where $\delta_{\inputVar, \inputVar'}$ is the Kronecker delta function, $I_0$ is the modified Bessel function of the first kind of order zero and other symbols are parameters of the kernel functions.

\subsection{Changepoints and changewindows}

The changepoint, $\kCP(\cdot,\cdot)$ operator is defined as follows:
\begin{align}
\kCP(\kernel_1, \kernel_2)(x, x') = \qquad \qquad \sigma(x) & k_1(x,x')\sigma(x') \nonumber \\ + (1-\sigma(x)) & k_2(x,x')(1-\sigma(x'))
\end{align}
where $\sigma(x) = 0.5 \times (1 + \tanh(\frac{\ell - x}{s}))$.
This can also be written as
\begin{align}
\kCP(\kernel_1, \kernel_2) = \boldsymbol\sigma\kernel_1 + \boldsymbol{\bar\sigma}\kernel_2
\end{align}
where $\boldsymbol\sigma(x,x') = \sigma(x)\sigma(x')$ and $\boldsymbol{\bar\sigma}(x,x') = (1-\sigma(x))(1-\sigma(x'))$.

Changewindow, $\kCW(\cdot,\cdot)$, operators are defined similarly by replacing the sigmoid, $\sigma(x)$, with a product of two sigmoids.

\subsection{Properties of the periodic kernel}

A simple application of l'H\^opital's rule shows that
\begin{equation}
\kPer(x, x') \to \sigma^2\cos\left(\frac{2 \pi (x - x')}{p}\right) \quad \textrm{as} \quad\ell \to \infty.
\end{equation}
This limiting form is written as the cosine kernel ($\cos$).
%It was recently demonstrated \citep{WilAda13} that any stationary kernel can be arbitrarily well approximated by kernels with syntax\fTBD{RG: Syntax $\to$ expression, structure, family?}
%\begin{equation}
%\sum \kSE \times \cos
%\end{equation}
%by appealing to Bochner's theorem \citep{bochner1959lectures}.
%By using this new periodic kernel our language of kernels also attains this completeness property.

\section{Model construction / search}

\subsection{Overview}

The model construction phase of \procedurename{} starts with the kernel equal to the noise kernel, $\kWN$.
New kernel expressions are generated by applying search operators to the current kernel.
When new base kernels are proposed by the search operators, their parameters are randomly initialised with several restarts.
Parameters are then optimized by conjugate gradients to maximise the likelihood of the data conditioned on the kernel parameters.
The kernels are then scored by the Bayesian information criterion and the top scoring kernel is selected as the new kernel.
The search then proceeds by applying the search operators to the new kernel \ie this is a greedy search algorithm.

In all experiments, 10 random restarts were used for parameter initialisation and the search was run to a depth of 10.

\subsection{Search operators}

\procedurename{} is based on a search algorithm which used the following search operators
%
\begin{eqnarray}
\mathcal{S} &\to& \mathcal{S} + \mathcal{B} \\
\mathcal{S} &\to& \mathcal{S} \times \mathcal{B} \\
\mathcal{B} &\to& \mathcal{B'}
\end{eqnarray}
%
where $\mathcal{S}$ represents any kernel subexpression and $\mathcal{B}$ is any base kernel within a kernel expression \ie the search operators represent addition, multiplication and replacement.

To accommodate changepoint/window operators we introduce the following additional operators
%
\begin{eqnarray}
\mathcal{S} &\to& \kCP(\mathcal{S},\mathcal{S}) \\
\mathcal{S} &\to& \kCW(\mathcal{S},\mathcal{S}) \\
\mathcal{S} &\to& \kCW(\mathcal{S},\kC) \\
\mathcal{S} &\to& \kCW(\kC,\mathcal{S})
\end{eqnarray}
%
where $\kC$ is the constant kernel.
The last two operators result in a kernel only applying outside or within a certain region.

Based on experience with typical paths followed by the search algorithm we introduced the following operators
%
\begin{eqnarray}
\mathcal{S} &\to& \mathcal{S} \times (\mathcal{B} + \kC)\\
\mathcal{S} &\to& \mathcal{B}\\
\mathcal{S} + \mathcal{S'} &\to& \mathcal{S}\\
\mathcal{S} \times \mathcal{S'} &\to& \mathcal{S}
\end{eqnarray}
%
where $\mathcal{S'}$ represents any other kernel expression.
Their introduction is currently not rigorously justified.

\section{Predictive accuracy}

\paragraph{Interpolation}

To test the ability of the methods to interpolate, we randomly divided each data set into equal amounts of training data and testing data.
We trained each algorithm on the training half of the data, produced predictions for the remaining half and then computed the root mean squared error (RMSE).
The values of the RMSEs are then standardised by dividing by the smallest RMSE for each data set \ie the best performance on each data set will have a value of 1.

Figure~\ref{fig:box_interp} shows the standardised RMSEs for the different algorithms.
The box plots show that all quartiles of the distribution of standardised RMSEs are lower for both versions of \procedurename{}.
The median for \procedurename{}-accuracy is 1; it is the best performing algorithm on 7 datasets.
The largest outliers of \procedurename{} and spectral kernels are similar in value.

\begin{figure*}[ht]
\centering
\includegraphics[width=\textwidth]{\grammarfiguresdir/comparison/box_interp}
\caption[Comparision of extrapolation error of all methods on 13 time-series datasets.]
{Box plot of standardised RMSE (best performance = 1) on 13 interpolation tasks.}
\label{fig:box_interp}
\end{figure*}

Changepoints performs slightly worse than MKL despite being strictly more general than Changepoints.
The introduction of changepoints allows for more structured models, but it introduces parametric forms into the regression models (\ie the sigmoids expressing the changepoints).
This results in worse interpolations at the locations of the change points, suggesting that a more robust modeling language would require a more flexible class of changepoint shapes or improved inference (\eg fully Bayesian inference over the location and shape of the changepoint).

Eureqa is not suited to this task and performs poorly.
The models learned by Eureqa tend to capture only broad trends of the data since the fine details are not well explained by parametric forms.

\subsection{Tabels of standardised RMSEs}

See table~\ref{table:interp} for raw interpolation results and table~\ref{table:extrap} for raw extrapolation results. 
The rows follow the order of the datasets in the rest of the supplementary material.
The following abbreviations are used: \procedurename{}-accuracy (\procedurename{}-acc), \procedurename{}-interpretability ((\procedurename{}-int), Spectral kernels (SP), Trend-cyclical-irregular (TCI), Bayesian MKL (MKL), Eureqa (EL), Changepoints (CP), Squared exponential (SE) and Linear regression (Lin).

\begin{table*}[ht]
\center
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\procedurename{}-acc & \procedurename{}-int & SP & TCI & MKL & EL & CP & SE & Lin \\
\hline
1.04 & 1.00 & 2.09 & 1.32 & 3.20 & 5.30 & 3.25 & 4.87 & 5.01\\
1.00 & 1.27 & 1.09 & 1.50 & 1.50 & 3.22 & 1.75 & 2.75 & 3.26\\
1.00 & 1.00 & 1.09 & 1.00 & 2.69 & 26.20 & 2.69 & 7.93 & 10.74\\
1.09 & 1.04 & 1.00 & 1.00 & 1.00 & 1.59 & 1.37 & 1.33 & 1.55\\
1.00 & 1.06 & 1.08 & 1.06 & 1.01 & 1.49 & 1.01 & 1.07 & 1.58\\
1.50 & 1.00 & 2.19 & 1.37 & 2.09 & 7.88 & 2.23 & 6.19 & 7.36\\
1.55 & 1.50 & 1.02 & 1.00 & 1.00 & 2.40 & 1.52 & 1.22 & 6.28\\
1.00 & 1.30 & 1.26 & 1.24 & 1.49 & 2.43 & 1.49 & 2.30 & 3.20\\
1.00 & 1.09 & 1.08 & 1.06 & 1.30 & 2.84 & 1.29 & 2.81 & 3.79\\
1.08 & 1.00 & 1.15 & 1.19 & 1.23 & 42.56 & 1.38 & 1.45 & 2.70\\
1.13 & 1.00 & 1.42 & 1.05 & 2.44 & 3.29 & 2.96 & 2.97 & 3.40\\
1.00 & 1.15 & 1.76 & 1.20 & 1.79 & 1.93 & 1.79 & 1.81 & 1.87\\
1.00 & 1.10 & 1.03 & 1.03 & 1.03 & 2.24 & 1.02 & 1.77 & 9.97\\
\hline
\end{tabular}
\caption[Interpolation error]{Interpolation standardised RMSEs}
\label{table:interp}
\end{table*}

\begin{table*}[ht]
\center
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\procedurename{}-acc & \procedurename{}-int & SP & TCI & MKL & EL & CP & SE & Lin \\
\hline
1.14 & 2.10 & 1.00 & 1.44 & 4.73 & 3.24 & 4.80 & 32.21 & 4.94\\
1.00 & 1.26 & 1.21 & 1.03 & 1.00 & 2.64 & 1.03 & 1.61 & 1.07\\
1.40 & 1.00 & 1.32 & 1.29 & 1.74 & 2.54 & 1.74 & 1.85 & 3.19\\
1.07 & 1.18 & 3.00 & 3.00 & 3.00 & 1.31 & 1.00 & 3.03 & 1.02\\
1.00 & 1.00 & 1.03 & 1.00 & 1.35 & 1.28 & 1.35 & 2.72 & 1.51\\
1.00 & 2.03 & 3.38 & 2.14 & 4.09 & 6.26 & 4.17 & 4.13 & 4.93\\
2.98 & 1.00 & 11.04 & 1.80 & 1.80 & 493.30 & 3.54 & 22.63 & 28.76\\
3.10 & 1.88 & 1.00 & 2.31 & 3.13 & 1.41 & 3.13 & 8.46 & 4.31\\
1.00 & 2.05 & 1.61 & 1.52 & 2.90 & 2.73 & 3.14 & 2.85 & 2.64\\
1.00 & 1.45 & 1.43 & 1.80 & 1.61 & 1.97 & 2.25 & 1.08 & 3.52\\
2.16 & 2.03 & 3.57 & 2.23 & 1.71 & 2.23 & 1.66 & 1.89 & 1.00\\
1.06 & 1.00 & 1.54 & 1.56 & 1.85 & 1.93 & 1.84 & 1.66 & 1.96\\
3.03 & 4.00 & 3.63 & 3.12 & 3.16 & 1.00 & 5.83 & 5.35 & 4.25\\
\hline
\end{tabular}
\caption[Extrapolation error]{Extrapolation standardised RMSEs}
\label{table:extrap}
\end{table*}



\outbpdocument{
\bibliographystyle{plainnat}
\bibliography{references.bib}
}


\iffalse

\section{Guide to the automatically generated reports}

Additional supplementary material to this paper is 13 reports automatically generated by \procedurename{}.
A link to these reports will be maintained at \url{http://mlg.eng.cam.ac.uk/lloyd/}.
We recommend that you read the report for `01-airline' first and review the reports that follow afterwards more briefly.
`02-solar' is discussed in the main text.
`03-mauna' analyses a dataset mentioned in the related work.
`04-wheat' demonstrates changepoints being used to capture heteroscedasticity.
`05-temperature' extracts an exactly periodic pattern from noisy data.
`07-call-centre' demonstrates a large discontinuity being modeled by a changepoint.
`10-sulphuric' combines many changepoints to create a highly structured model of the data.
`12-births' discovers multiple periodic components.

\fi
